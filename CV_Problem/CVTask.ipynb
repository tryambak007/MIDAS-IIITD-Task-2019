{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVTask.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "5aaIjELtEfTn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** File Reading **\n",
        "\n",
        "Here in this notebook, I have illustrated the steps to build a model to classify a image dataset into 4 different classes.\n",
        "\n",
        "It is observed that the dataset files is in **.pkl** format. Thus we need to import pickle library of python and fetch the data from the files. "
      ]
    },
    {
      "metadata": {
        "id": "pMj9xhmkNgaP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('train_image.pkl', 'rb') as f:\n",
        "    train_X = pickle.load(f)                        # train_X stores the raw image data obtained from train_image.pkl file\n",
        "with open('train_label.pkl', 'rb') as f:\n",
        "    train_Y = pickle.load(f)                        # train_Y stores the image labels of training set obtained from train_label.pkl file\n",
        "with open('test_image.pkl', 'rb') as f:\n",
        "    test_X = pickle.load(f)                         # test_X stores the raw image data of test set obtained from test_image.pkl file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "js7Mbz2UNqDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing Required Libraries**\n",
        "\n",
        "Next, I will be importing all necessary packages for creating a network and preprocessing. I will be using a CNN to classify the images into various classes. The requirement of imported libraries are as follows: \n",
        "\n",
        "1.   **Keras** : For building the model.\n",
        "2.   **Scikit Learn** : For spliting the dataset into training and validation set.\n",
        "3.   **NumPy** : For handling image matrices.\n",
        "4. **Pandas** : For handling csv files.\n",
        "5. **MatPlotLib** : For displaying some images. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "VZFIbQQWN2gL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_d_KeTywPGwr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Preprocessing Steps**\n",
        "\n",
        "We will have to convert the raw image and label data into NumPy arrays. Also, we shall be display one of the pictures from the training dataset."
      ]
    },
    {
      "metadata": {
        "id": "yFCt_JRZWHUD",
        "colab_type": "code",
        "outputId": "b611a5db-551b-4293-a1d1-69847ead28a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "cell_type": "code",
      "source": [
        "X_orig = np.asarray(train_X, dtype=None, order=None) # Conversion into numpy array\n",
        "Y_orig = np.asarray(train_Y, dtype=None, order=None) # Conversion into numpy array\n",
        "print(X_orig.shape)\n",
        "t = X_orig[6119].reshape(28,28)\n",
        "plt.imshow(t, cmap=\"gray\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9ff92d7dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "40GMTaDQEEs2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following block does quite a few things. \n",
        "* Firstly, it converts each of the training example from a vector to 28x28x1 matrix which is required by the convolutional layer of the network as an input. Also, each of the image pixel values are rescaled by dividing by 255. \n",
        "* Secondly, it alters the labels. In order to use \"categorical crossentropy\" loss for multiclass classification, the labels should be in the form of a matrix of size (number of examples, number of classes).  This is done by *to_categorical* method. The number of classes is automatically determined by the maximum value of the label. In this case, since the labels take the values 0, 2, 3 and 6 even though only 4 classes are present. Hence label values are altered in the following way : 0 -> 0 ; 2 -> 1, 3 -> 2, 6 -> 4.\n",
        "* Finally, the training set and its labels are split into training and validation set. The validation set is made  of 20% of the training set. Scikit-learn function *train_test_split* is used for this purpose.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "MPE6uezhO4IY",
        "colab_type": "code",
        "outputId": "3601e51e-3b71-4ab5-8756-93dd2e96d40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "train_image = []\n",
        "for i in range(X_orig.shape[0]):                                                             # loop for altering image data\n",
        "  img = X_orig[i].reshape(28,28,1)\n",
        "  img = img / 255;\n",
        "  train_image.append(img)\n",
        "X1 = np.array(train_image)\n",
        "for i in range(Y_orig.shape[0]):                                                             # loop for altering labels\n",
        "  if Y_orig[i] == 2:\n",
        "    Y_orig[i] = 1\n",
        "  elif Y_orig[i] == 3:\n",
        "    Y_orig[i] = 2\n",
        "  elif Y_orig[i] == 6:\n",
        "    Y_orig[i] = 3\n",
        "Y1 = to_categorical(Y_orig,num_classes=4)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1, Y1, random_state=42, test_size=0.2)   # split into training and validation set\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train[1090])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6400, 28, 28, 1)\n",
            "(1600, 28, 28, 1)\n",
            "(6400, 4)\n",
            "(1600, 4)\n",
            "[0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uSmm3hEkHlUq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Network Creation **\n",
        "\n",
        "Now, the model needs to be defined. For this case, I will be using a Convolutional Neural Network."
      ]
    },
    {
      "metadata": {
        "id": "J1Upka9YQ8km",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_network():\n",
        "  model = Sequential()                                                                 # make a sequential model\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(28,28,1)))    # add a convolutional layer\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))                                    \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))                                            # add maxpooling layer\n",
        "  model.add(Dropout(0.25))                                                             # set regularization type to dropout to prevent overfitting with drop probability 25%\n",
        "  model.add(Flatten())                                                                 # changes input from matrix to vectors for feeding it into dense layers\n",
        "  model.add(Dense(128, activation='relu'))                                             # add a dense layer\n",
        "  model.add(Dropout(0.5))                                                              # set dropout probability of layer to 50%\n",
        "  model.add(Dense(4, activation='softmax'))                                            # add dense layer\n",
        "  model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy']) # set loss function as categorical crossentropy \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7lXJhxnMhQ-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Training the Network **\n",
        "\n",
        "The following block trains the network on the training data and validates it over validation set."
      ]
    },
    {
      "metadata": {
        "id": "txQHpG2wRQne",
        "colab_type": "code",
        "outputId": "9c4b9275-db46-4bb3-fdfa-b4b81c54a0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "cell_type": "code",
      "source": [
        "model  = generate_network()\n",
        "model.fit(X_train, y_train, epochs=15, validation_data=(X_test, y_test))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 1600 samples\n",
            "Epoch 1/15\n",
            "6400/6400 [==============================] - 22s 3ms/step - loss: 0.6442 - acc: 0.7445 - val_loss: 0.4708 - val_acc: 0.8106\n",
            "Epoch 2/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.4584 - acc: 0.8214 - val_loss: 0.4212 - val_acc: 0.8287\n",
            "Epoch 3/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.3975 - acc: 0.8402 - val_loss: 0.3968 - val_acc: 0.8375\n",
            "Epoch 4/15\n",
            "6400/6400 [==============================] - 22s 3ms/step - loss: 0.3467 - acc: 0.8623 - val_loss: 0.3895 - val_acc: 0.8438\n",
            "Epoch 5/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.3261 - acc: 0.8730 - val_loss: 0.3783 - val_acc: 0.8494\n",
            "Epoch 6/15\n",
            "6400/6400 [==============================] - 22s 3ms/step - loss: 0.2991 - acc: 0.8841 - val_loss: 0.3748 - val_acc: 0.8494\n",
            "Epoch 7/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.2762 - acc: 0.8931 - val_loss: 0.3794 - val_acc: 0.8450\n",
            "Epoch 8/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.2500 - acc: 0.9016 - val_loss: 0.3722 - val_acc: 0.8538\n",
            "Epoch 9/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.2277 - acc: 0.9161 - val_loss: 0.3701 - val_acc: 0.8700\n",
            "Epoch 10/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.2031 - acc: 0.9208 - val_loss: 0.3672 - val_acc: 0.8600\n",
            "Epoch 11/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.1858 - acc: 0.9313 - val_loss: 0.4287 - val_acc: 0.8594\n",
            "Epoch 12/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.1754 - acc: 0.9284 - val_loss: 0.4037 - val_acc: 0.8644\n",
            "Epoch 13/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.1600 - acc: 0.9400 - val_loss: 0.4289 - val_acc: 0.8606\n",
            "Epoch 14/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.1386 - acc: 0.9431 - val_loss: 0.4056 - val_acc: 0.8719\n",
            "Epoch 15/15\n",
            "6400/6400 [==============================] - 21s 3ms/step - loss: 0.1207 - acc: 0.9531 - val_loss: 0.4573 - val_acc: 0.8675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9ff846a8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "3B5VJV0SL-GC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Test data preprocessing **\n",
        "\n",
        "Now that the model has already been trained, we will use it to predict on test dataset. Before that we need to process the test data in the same way we have done with the training data by rescaling and reshaping."
      ]
    },
    {
      "metadata": {
        "id": "ezoaUX-oX7c4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_X = np.asarray(test_X, dtype=None, order=None)\n",
        "test_image = []\n",
        "for i in range(test_X.shape[0]):\n",
        "  img = test_X[i].reshape(28,28,1)\n",
        "  img = img / 255;\n",
        "  test_image.append(img)\n",
        "test_X = np.array(test_image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KrON6XU5MzFh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Predicting **\n",
        "\n",
        "The trained model will predict on the test dataset."
      ]
    },
    {
      "metadata": {
        "id": "zkSTm-CkyEg8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction = model.predict_classes(test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0MWl9XxrM6js",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The classes that the model predicts are 0, 1, 2 and 3 corresponding to the required 0, 2, 3, 6. So the predicted values are adjusted accordingly."
      ]
    },
    {
      "metadata": {
        "id": "lS7f_muKyMKP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(len(prediction)):\n",
        "  if prediction[i]==1:\n",
        "    prediction[i] = 2\n",
        "  elif prediction[i] == 2:\n",
        "    prediction[i] = 3\n",
        "  elif prediction[i] == 3:\n",
        "    prediction[i] = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-satW4HePojv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Storing predictions **\n",
        "\n",
        "The predicted values are now put inside a pandas dataframe in order to facilitate saving to a csv files. The column representing image index values is named \"test_image_index\" and the column representing predicted classes has name \"predicted_class\" ."
      ]
    },
    {
      "metadata": {
        "id": "BVq_L9HxyQy4",
        "colab_type": "code",
        "outputId": "6a78071c-1ba2-45ef-f93a-51e0a7f4012d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(prediction)\n",
        "df.index.name=\"test_image_index\"\n",
        "df.columns=[\"predicted class\"]\n",
        "print(df)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  predicted class\n",
            "test_image_index                 \n",
            "0                               0\n",
            "1                               0\n",
            "2                               0\n",
            "3                               0\n",
            "4                               0\n",
            "5                               0\n",
            "6                               0\n",
            "7                               0\n",
            "8                               0\n",
            "9                               0\n",
            "10                              0\n",
            "11                              0\n",
            "12                              0\n",
            "13                              0\n",
            "14                              0\n",
            "15                              0\n",
            "16                              0\n",
            "17                              0\n",
            "18                              0\n",
            "19                              0\n",
            "20                              0\n",
            "21                              0\n",
            "22                              0\n",
            "23                              0\n",
            "24                              0\n",
            "25                              0\n",
            "26                              0\n",
            "27                              0\n",
            "28                              0\n",
            "29                              0\n",
            "...                           ...\n",
            "1970                            6\n",
            "1971                            6\n",
            "1972                            6\n",
            "1973                            0\n",
            "1974                            6\n",
            "1975                            6\n",
            "1976                            6\n",
            "1977                            6\n",
            "1978                            6\n",
            "1979                            6\n",
            "1980                            6\n",
            "1981                            6\n",
            "1982                            6\n",
            "1983                            6\n",
            "1984                            3\n",
            "1985                            6\n",
            "1986                            6\n",
            "1987                            6\n",
            "1988                            6\n",
            "1989                            6\n",
            "1990                            6\n",
            "1991                            0\n",
            "1992                            6\n",
            "1993                            6\n",
            "1994                            3\n",
            "1995                            6\n",
            "1996                            6\n",
            "1997                            6\n",
            "1998                            6\n",
            "1999                            6\n",
            "\n",
            "[2000 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eoA4VNEvQYku",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The created dataframe is now saved as a **.csv** file with name \"tryambak_bhattacharjee.csv\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "t86m2vUVbynz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.to_csv('tryambak_bhattacharjee.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}